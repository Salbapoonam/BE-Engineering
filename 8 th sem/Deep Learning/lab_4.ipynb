{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion-MNIST Classification using Neural Network\n",
    "\n",
    "In this notebook, we'll build a neural network to classify Fashion-MNIST images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy._utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10668/1674168867.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\soft\\anaconda\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_globals\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_NoValue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_CopyMode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;31m# These exceptions were moved in 1.25 and are hidden from __dir__()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m from .exceptions import (\n",
      "\u001b[1;32mE:\\soft\\anaconda\\lib\\site-packages\\numpy\\_globals.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0menum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_module\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_set_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'_NoValue'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_CopyMode'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy._utils'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Download training and testing data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "train_ds = datasets.FashionMNIST('F_MNIST_data', download=True, train=True, transform=transform)\n",
    "test_ds = datasets.FashionMNIST('F_MNIST_data', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train set into training (80%) and validation set (20%)\n",
    "train_num = len(train_ds)\n",
    "indices = list(range(train_num))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(0.2 * train_num))\n",
    "val_idx, train_idx = indices[:split], indices[split:]\n",
    "len(val_idx), len(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataloaders\n",
    "train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_idx)\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=64, sampler=train_sampler)\n",
    "val_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_idx)\n",
    "val_dl = torch.utils.data.DataLoader(train_ds, batch_size=64, sampler=val_sampler)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(train_dl))\n",
    "print(image[0].shape, label.shape)\n",
    "desc = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot']\n",
    "print(desc[label[0].item()])\n",
    "plt.imshow(image[0].numpy().squeeze(), cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network():\n",
    "    model = nn.Sequential(OrderedDict([('fc1', nn.Linear(784, 128)),\n",
    "                                       ('relu1', nn.ReLU()),\n",
    "                                       ('drop1', nn.Dropout(0.25)),                                       \n",
    "                                       ('fc2', nn.Linear(128, 64)),\n",
    "                                       ('relu2', nn.ReLU()),\n",
    "                                       ('drop1', nn.Dropout(0.25)),                                       \n",
    "                                       ('output', nn.Linear(64, 10)),\n",
    "                                       ('logsoftmax', nn.LogSoftmax(dim=1))]))\n",
    "    # Use GPU if available\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "\n",
    "    # define the criterion and optimizer\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "    return model, loss_fn, optimizer, device                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, loss_fn, optimizer, device = network()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate(model, loss_fn, optimizer, trainloader, testloader, device, n_epochs=25):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        # Set mode to training - Dropouts will be used here\n",
    "        model.train()\n",
    "        train_epoch_loss = 0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # flatten the images to batch_size x 784\n",
    "            images = images.view(images.shape[0], -1)\n",
    "            # forward pass\n",
    "            outputs = model(images)\n",
    "            # backpropogation\n",
    "            train_batch_loss = loss_fn(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            train_batch_loss.backward()\n",
    "            # Weight updates\n",
    "            optimizer.step()\n",
    "            train_epoch_loss += train_batch_loss.item()\n",
    "        else:\n",
    "            # One epoch of training complete\n",
    "            # calculate average training epoch loss\n",
    "            train_epoch_loss = train_epoch_loss/len(trainloader)\n",
    "\n",
    "            # Now Validate on testset\n",
    "            with torch.no_grad():\n",
    "                test_epoch_acc = 0\n",
    "                test_epoch_loss = 0\n",
    "                # Set mode to eval - Dropouts will NOT be used here\n",
    "                model.eval()\n",
    "                for images, labels in testloader:\n",
    "                    images, labels = images.to(device), labels.to(device)                    \n",
    "                    # flatten images to batch_size x 784\n",
    "                    images = images.view(images.shape[0], -1)\n",
    "                    # make predictions \n",
    "                    test_outputs = model(images)\n",
    "                    # calculate test loss\n",
    "                    test_batch_loss = loss_fn(test_outputs, labels)\n",
    "                    test_epoch_loss += test_batch_loss\n",
    "                    \n",
    "                    # get probabilities, extract the class associated with highest probability\n",
    "                    proba = torch.exp(test_outputs)\n",
    "                    _, pred_labels = proba.topk(1, dim=1)\n",
    "                    \n",
    "                    # compare actual labels and predicted labels\n",
    "                    result = pred_labels == labels.view(pred_labels.shape)\n",
    "                    batch_acc = torch.mean(result.type(torch.FloatTensor))\n",
    "                    test_epoch_acc += batch_acc.item()\n",
    "                else:\n",
    "                    # One epoch of training and validation done\n",
    "                    # calculate average testing epoch loss\n",
    "                    test_epoch_loss = test_epoch_loss/len(testloader)\n",
    "                    # calculate accuracy as correct_pred/total_samples\n",
    "                    test_epoch_acc = test_epoch_acc/len(testloader)\n",
    "                    # save epoch losses for plotting\n",
    "                    train_losses.append(train_epoch_loss)\n",
    "                    test_losses.append(test_epoch_loss)\n",
    "                    # print stats for this epoch\n",
    "                    print(f'Epoch: {epoch} -> train_loss: {train_epoch_loss:.19f}, val_loss: {test_epoch_loss:.19f}, ',\n",
    "                          f'val_acc: {test_epoch_acc*100:.2f}%')\n",
    "    # Finally plot losses\n",
    "    plt.plot(train_losses, label='train-loss')\n",
    "    plt.plot(test_losses, label='val-loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validate\n",
    "train_validate(model, loss_fn, optimizer, train_dl, val_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Test out the network!\n",
    "dataiter = iter(test_dl)\n",
    "images, labels = dataiter.next()\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "index = 49\n",
    "img, label = images[index], labels[index]\n",
    "# Convert 2D image to 1D vector\n",
    "img = img.view(img.shape[0], -1)\n",
    "\n",
    "# Calculate the class probabilities (softmax) for img\n",
    "proba = torch.exp(model(img))\n",
    "\n",
    "# Plot the image and probabilities\n",
    "desc = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot']\n",
    "fig, (ax1, ax2) =  plt.subplots(figsize=(13, 6), nrows=1, ncols=2)\n",
    "ax1.axis('off')\n",
    "ax1.imshow(images[index].cpu().numpy().squeeze())\n",
    "ax1.set_title(desc[label.item()])\n",
    "ax2.bar(range(10), proba.detach().cpu().numpy().squeeze())\n",
    "ax2.set_xticks(range(10))\n",
    "ax2.set_xticklabels(desc, size='small')\n",
    "ax2.set_title('Predicted Probabilities')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate\n",
    "with torch.no_grad():\n",
    "    batch_acc = []\n",
    "    model.eval()\n",
    "    for images, labels in test_dl:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # flatten images to batch_size x 784\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        # make predictions and get probabilities\n",
    "        proba = torch.exp(model(images))\n",
    "        # extract the class associted with highest probability\n",
    "        _, pred_labels = proba.topk(1, dim=1)\n",
    "        # compare actual labels and predicted labels\n",
    "        result = pred_labels == labels.view(pred_labels.shape)\n",
    "        acc = torch.mean(result.type(torch.FloatTensor))\n",
    "        batch_acc.append(acc.item())\n",
    "    else:\n",
    "        print(f'Test Accuracy: {torch.mean(torch.tensor(batch_acc))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More powerful model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine network with dropout layers in between\n",
    "def network():\n",
    "    model = nn.Sequential(OrderedDict([('fc1', nn.Linear(784, 392)),\n",
    "                                       ('relu1', nn.ReLU()),\n",
    "                                       ('drop1', nn.Dropout(0.25)),\n",
    "                                       ('fc12', nn.Linear(392, 196)),\n",
    "                                       ('relu2', nn.ReLU()),\n",
    "                                       ('drop2', nn.Dropout(0.25)),\n",
    "                                       ('fc3', nn.Linear(196, 98)),\n",
    "                                       ('relu3', nn.ReLU()),\n",
    "                                       ('drop3', nn.Dropout(0.25)),                                       \n",
    "                                       ('fc4', nn.Linear(98, 49)),\n",
    "                                       ('relu4', nn.ReLU()),\n",
    "                                       ('output', nn.Linear(49, 10)),\n",
    "                                       ('logsoftmax', nn.LogSoftmax(dim=1))]))\n",
    "    \n",
    "    # Use GPU if available\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "\n",
    "    # define the criterion and optimizer\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0007)\n",
    "\n",
    "    return model, loss_fn, optimizer, device       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, loss_fn, optimizer, device = network()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validate again with new architecture\n",
    "train_validate(model, loss_fn, optimizer, train_dl, val_dl, device, n_epochs=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    batch_acc = []\n",
    "    for images, labels in test_dl:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # flatten images to batch_size x 784\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        # make predictions and get probabilities\n",
    "        proba = torch.exp(model(images))\n",
    "        # extract the class associted with highest probability\n",
    "        _, pred_labels = proba.topk(1, dim=1)\n",
    "        # compare actual labels and predicted labels\n",
    "        result = pred_labels == labels.view(pred_labels.shape)\n",
    "        acc = torch.mean(result.type(torch.FloatTensor))\n",
    "        batch_acc.append(acc.item())\n",
    "    else:\n",
    "        print(f'Accuracy: {torch.mean(torch.tensor(batch_acc))*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
